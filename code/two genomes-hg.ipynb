{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run regression_code.py\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Choose visible device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "# Select model number. From 0 to 4, as much as number of folds\n",
    "MODEL_NUMBER = 0\n",
    "# Choose experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSEMBLY_d = {}\n",
    "chroms_d = {}\n",
    "all_features_d = {}\n",
    "groups_d = {}\n",
    "feature_names_d = {}\n",
    "ZDNA_d = {}\n",
    "black_list_d = {}\n",
    "DNA_d = {}\n",
    "DNA_features_d = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSEMBLY = \"curax_14h_UNI_mm9\"\n",
    "chroms = [f'chr{i}' for i in list(range(1, 20)) + ['X', 'Y']]\n",
    "all_features = sorted([i[:-4] for i in os.listdir('../data/mm9_features/sparse/') if i.endswith('.pkl')])\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in all_features if (i.split('_')[0] in groups)]\n",
    "ZDNA = load(f'../data/mm9_zdna/sparse/{ASSEMBLY}.pkl')\n",
    "black_list = load(f'../data/mm9_zdna/sparse/blacklist_mm9.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA = {chrom:load(f'../data/mm9_dna/sparse/{chrom}.pkl') for chrom in tqdm(chroms)}\n",
    "\n",
    "DNA_features = {feture: load(f'../data/mm9_features/sparse/{feture}.pkl')\n",
    "                for feture in tqdm(feature_names)}\n",
    "\n",
    "for feature in tqdm(DNA_features):\n",
    "    if set(DNA_features[feature].keys()) != set(chroms):\n",
    "        for chrom in chroms:\n",
    "            if chrom not in DNA_features[feature]:\n",
    "                DNA_features[feature][chrom] = SparseVector(len(DNA[chrom]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'mm9'\n",
    "ASSEMBLY_d[mode] = ASSEMBLY\n",
    "chroms_d[mode] = chroms\n",
    "all_features_d[mode] = all_features\n",
    "groups_d[mode] = groups\n",
    "feature_names_d[mode] = feature_names\n",
    "ZDNA_d[mode] = ZDNA\n",
    "black_list_d[mode] = black_list\n",
    "DNA_d[mode] = DNA\n",
    "DNA_features_d[mode] = DNA_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSEMBLY = \"ZDNA_2016\"\n",
    "chroms = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y']]\n",
    "all_features = sorted([i[:-4] for i in os.listdir('../data/hg19_features/sparse/') if i.endswith('.pkl')])\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in all_features if (i.split('_')[0] in groups)]\n",
    "ZDNA = load(f'../data/hg19_zdna/sparse/{ASSEMBLY}.pkl')\n",
    "black_list = load(f'../data/hg19_zdna/sparse/blacklist_hg19.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA = {chrom:load(f'../data/hg19_dna/sparse/{chrom}.pkl') for chrom in tqdm(chroms)}\n",
    "\n",
    "DNA_features = {feture: load(f'../data/hg19_features/sparse/{feture}.pkl')\n",
    "                for feture in tqdm(feature_names)}\n",
    "\n",
    "for feature in tqdm(DNA_features):\n",
    "    if set(DNA_features[feature].keys()) != set(chroms):\n",
    "        for chrom in chroms:\n",
    "            if chrom not in DNA_features[feature]:\n",
    "                DNA_features[feature][chrom] = SparseVector(len(DNA[chrom]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'hg19'\n",
    "ASSEMBLY_d[mode] = ASSEMBLY\n",
    "chroms_d[mode] = chroms\n",
    "all_features_d[mode] = all_features\n",
    "groups_d[mode] = groups\n",
    "feature_names_d[mode] = feature_names\n",
    "ZDNA_d[mode] = ZDNA\n",
    "black_list_d[mode] = black_list\n",
    "DNA_d[mode] = DNA\n",
    "DNA_features_d[mode] = DNA_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect = {i.upper() for i in DNA_features_d['mm9']} & {i.upper() for i in DNA_features_d['hg19']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'hg19'\n",
    "ASSEMBLY = ASSEMBLY_d[mode]\n",
    "chroms = chroms_d[mode]\n",
    "all_features = all_features_d[mode]\n",
    "groups = groups_d[mode]\n",
    "feature_names = feature_names_d[mode]\n",
    "ZDNA = ZDNA_d[mode]\n",
    "black_list = black_list_d[mode]\n",
    "DNA = DNA_d[mode]\n",
    "DNA_features = DNA_features_d[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1000\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "\n",
    "for chrm in chroms:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        N_count = sum([bp == \"N\" for bp in DNA[chrm][interval[0]:interval[1]]])\n",
    "        bl_count = black_list[chrm][interval[0]:interval[1]].sum()\n",
    "        if N_count > width / 2 or bl_count > 0:\n",
    "            continue\n",
    "        else:\n",
    "            if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "                ints_in.append([chrm, int(interval[0]), int(interval[1]), 1])\n",
    "            else:\n",
    "                ints_out.append([chrm, int(interval[0]), int(interval[1]), 0])\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "print(len(ints_in))\n",
    "print(len(ints_out))\n",
    "\n",
    "ints_in_full = ints_in\n",
    "ints_out_full = ints_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints_in = ints_in_full\n",
    "ints_out = [ints_out_full[i] for i in np.random.choice(range(len(ints_out_full)), \n",
    "                                                    size=len(ints_in) * 20, replace=False)]\n",
    "# ints_out = ints_out_full\n",
    "\n",
    "print(len(ints_in))\n",
    "print(len(ints_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = ints_in + ints_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = list(StratifiedKFold(5, shuffle=True, \n",
    "                                 random_state=42).split(equalized, [f\"{elem[3]}_{elem[0]}\"\n",
    "                                         for i, elem \n",
    "                                         in enumerate(equalized)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump([equalized, divisions], 'hg_divisions.pkl', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds, test_inds = divisions[MODEL_NUMBER]\n",
    "\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
    "\n",
    "random.shuffle(train_intervals)\n",
    "random.shuffle(test_intervals)\n",
    "\n",
    "\n",
    "train_dataset = Dataset(chroms, \n",
    "                        [i for i in feature_names if i.upper() in intersect], \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = Dataset(chroms, \n",
    "                       [i for i in feature_names if i.upper() in intersect], \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, test_intervals)\n",
    "\n",
    "params = {'batch_size':100,\n",
    "          'num_workers':5,\n",
    "          'shuffle':True}\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "\n",
    "\n",
    "params = {'batch_size':100,\n",
    "          'num_workers':5,\n",
    "          'shuffle':True}\n",
    "loader_test = data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class DeepZ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(592, 100, 1, bidirectional=True)\n",
    "        self.seq = nn.Sequential(\n",
    "                nn.Linear(2 * 100, 100),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(100, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, (h_n, c_n) = self.rnn(x)\n",
    "        x = self.seq(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size':200,\n",
    "          'num_workers':5,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "loader_test = data.DataLoader(test_dataset, **params)\n",
    "\n",
    "\n",
    "train_log, train_acc_log, train_auc_log, train_f1_log = [], [], [], []\n",
    "val_log,   val_acc_log,   val_auc_log, val_f1_log   = [], [], [], []\n",
    "# best_auc = 0\n",
    "# log = open(f\"../models/{ASSEMBLY}/log_{MODEL_NUMBER}\", 'w')\n",
    "# log.write(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") + \"\\n\")\n",
    "# log.close()\n",
    "    \n",
    "def loss_func(output, y_batch):\n",
    "    return torch.nn.NLLLoss()(torch.transpose(output, 2, 1), y_batch)\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
    "    model.train()\n",
    "    for X_batch, y_batch in tqdm(loader_train):\n",
    "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        pred = torch.argmax(output, dim=2)\n",
    "        y_pred = nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten()\n",
    "        if np.std(y_batch.cpu().numpy().flatten()) == 0:\n",
    "            roc_auc = 0\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_batch.cpu().numpy().flatten(),\n",
    "                                    nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten())\n",
    "        f1_log.append(f1_score(y_batch.cpu().numpy().flatten(),\n",
    "                         pred.cpu().numpy().flatten()))\n",
    "        roc_auc_log.append(roc_auc)\n",
    "        acc = torch.mean((pred == y_batch).float())\n",
    "        acc_log.append(acc.cpu().numpy())\n",
    "        loss = loss_func(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log, roc_auc_log, f1_log\n",
    "\n",
    "def test(model):\n",
    "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
    "    model.eval()\n",
    "    means = []\n",
    "    for X_batch, y_batch in tqdm(loader_test):\n",
    "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
    "        output = model(X_batch)\n",
    "        means.append(y_batch.sum().cpu() / (1.0 * y_batch.shape[0]))\n",
    "        pred = torch.argmax(output, dim=2)\n",
    "        if np.std(y_batch.cpu().numpy().flatten()) == 0:\n",
    "            roc_auc = 0\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_batch.cpu().numpy().flatten(),\n",
    "                                    nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten())\n",
    "        f1_log.append(f1_score(y_batch.cpu().numpy().flatten(),\n",
    "                                  pred.cpu().numpy().flatten()))\n",
    "        roc_auc_log.append(roc_auc)\n",
    "        acc = torch.mean((pred == y_batch).float())\n",
    "        acc_log.append(acc.cpu().numpy())\n",
    "        loss = loss_func(output, y_batch)\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log, roc_auc_log, f1_log\n",
    "\n",
    "def plot_history(train_history, valid_history, title, BatchSize, epoch_to_show=20):\n",
    "    plt.figure(figsize=(epoch_to_show, 4))\n",
    "    plt.title(title)    \n",
    "    \n",
    "    epoch_num = len(valid_history)\n",
    "    train_history = np.array([None] * (BatchSize * epoch_to_show) + train_history)\n",
    "    valid_history = np.array([None] * epoch_to_show + valid_history)\n",
    "    \n",
    "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, (epoch_to_show+1)*BatchSize), \n",
    "             train_history[-(epoch_to_show+1)*BatchSize:], c='red', label='train')\n",
    "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, epoch_to_show+1),\n",
    "                valid_history[-epoch_to_show-1:], c='green', label='test')\n",
    "    \n",
    "    plt.ylim((0, 1))\n",
    "    plt.yticks(np.linspace(0, 1, 11))\n",
    "    plt.xticks(np.arange(epoch_num-epoch_to_show+1, epoch_num+2), \n",
    "              np.arange(epoch_num-epoch_to_show, epoch_num+1).astype(int))\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs, loader_train, loader_test):\n",
    "    global best_auc\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {} of {}\".format(epoch + 1, n_epochs))\n",
    "        train_loss, train_acc, train_auc, train_f1 = train_epoch(model, opt)\n",
    "        val_loss, val_acc, val_auc, val_f1 = test(model)\n",
    "        \n",
    "        BatchSize = len(train_loss)\n",
    "        \n",
    "        train_log.extend(train_loss)\n",
    "        train_acc_log.extend(train_acc)\n",
    "        train_auc_log.extend(train_auc)\n",
    "        train_f1_log.extend(train_f1)\n",
    "\n",
    "        val_log.append(np.mean(val_loss))\n",
    "        val_acc_log.append(np.mean(val_acc))\n",
    "        val_auc_log.append(np.mean(val_auc))\n",
    "        val_f1_log.append(np.mean(val_f1))\n",
    "        \n",
    "        if (epoch % 1) == 0:\n",
    "            clear_output()\n",
    "            plot_history(train_log,     val_log,     'Loss',     BatchSize)    \n",
    "            plot_history(train_acc_log, val_acc_log, 'Accuracy', BatchSize)\n",
    "            plot_history(train_auc_log, val_auc_log, 'Auc',      BatchSize)\n",
    "            plot_history(train_f1_log, val_f1_log,   'F1',       BatchSize)\n",
    "            print(\"Epoch {} AUC = {:.2%}\".format(epoch+1, val_auc_log[-1]))\n",
    "            print(\"Epoch {} accuracy = {:.2%}\".format(epoch+1, val_acc_log[-1]))\n",
    "            \n",
    "#             if val_auc_log[-1] > best_auc:\n",
    "#                 best_auc = val_auc_log[-1]\n",
    "#                 torch.save(model.state_dict(), f\"../models/{ASSEMBLY}/model_{MODEL_NUMBER}\")\n",
    "#                 log = open(f\"../models/{ASSEMBLY}/log_{MODEL_NUMBER}\", 'a')\n",
    "#                 log.write(str(best_auc) + \"\\n\")\n",
    "#                 log.close()\n",
    "            \n",
    "    print(\"Final AUC: {:.2}\".format(1 - val_auc_log[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = DeepZ()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.RMSprop(model.parameters(), lr=10**-2, weight_decay=10**-4)\n",
    "train(model, opt, 5)\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=10**-3, weight_decay=10**-4)\n",
    "train(model, opt, 5)\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=10**-3/4, weight_decay=10**-4)\n",
    "train(model, opt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for MODEL_NUMBER in range(5):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_inds, test_inds = divisions[MODEL_NUMBER]\n",
    "\n",
    "\n",
    "    train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
    "\n",
    "    random.shuffle(train_intervals)\n",
    "    random.shuffle(test_intervals)\n",
    "\n",
    "\n",
    "    train_dataset = Dataset(chroms, \n",
    "                            [i for i in feature_names if i.upper() in intersect], \n",
    "                           DNA, DNA_features, \n",
    "                           ZDNA, train_intervals)\n",
    "\n",
    "    test_dataset = Dataset(chroms, \n",
    "                           [i for i in feature_names if i.upper() in intersect], \n",
    "                           DNA, DNA_features, \n",
    "                           ZDNA, test_intervals)\n",
    "\n",
    "    params = {'batch_size':200,\n",
    "              'num_workers':5,\n",
    "              'shuffle':True}\n",
    "    loader_train = data.DataLoader(train_dataset, **params)\n",
    "    loader_test = data.DataLoader(test_dataset, **params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model = DeepZ()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    train_log, train_acc_log, train_auc_log, train_f1_log = [], [], [], []\n",
    "    val_log,   val_acc_log,   val_auc_log, val_f1_log   = [], [], [], []\n",
    "    opt = torch.optim.RMSprop(model.parameters(), lr=10**-2, weight_decay=10**-5)\n",
    "    train(model, opt, 10, loader_train, loader_test)\n",
    "    opt = torch.optim.RMSprop(model.parameters(), lr=10**-3, weight_decay=10**-5)\n",
    "    train(model, opt, 10, loader_train, loader_test)\n",
    "    opt = torch.optim.RMSprop(model.parameters(), lr=10**-4, weight_decay=10**-5)\n",
    "    train(model, opt, 10, loader_train, loader_test)\n",
    "    torch.save(model.state_dict(), f'../models/models/new_mod_hg_{MODEL_NUMBER}.pkl')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
